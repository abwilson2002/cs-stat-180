{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rhodes-byu/cs-stat-180/blob/main/notebooks/03b-pandas-aggregation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><p><b>After clicking the \"Open in Colab\" link, copy the notebook to your own Google Drive before getting started, or it will not save your work</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyYhJfptDOSh"
   },
   "outputs": [],
   "source": [
    "# Import Pandas library\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuLGuAZSDOSk"
   },
   "outputs": [],
   "source": [
    "## Iris data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "iris = pd.read_csv(url, names=['sepal_length','sepal_width', 'petal_length', 'petal_width', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.rename(columns={'class': 'species'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJHMQ9bqDOSq"
   },
   "source": [
    "## Using Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R4Z4-TVDOSq"
   },
   "outputs": [],
   "source": [
    "iris['sepal_length'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bNrDTAXDOSq"
   },
   "outputs": [],
   "source": [
    "# What happened?\n",
    "iris['sepal_length'].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TGrpObFDOSq"
   },
   "outputs": [],
   "source": [
    "iris.iloc[:, 0:4].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCSdNVLHDOSq"
   },
   "outputs": [],
   "source": [
    "iris['species'].apply(lambda x: x.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4-TGxHFDOSq"
   },
   "outputs": [],
   "source": [
    "iris['species'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVGP50VIDOSq"
   },
   "outputs": [],
   "source": [
    "def zero_one_scale(x):\n",
    "    return (x - np.min(x)) / (np.max(x)- np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why does this not work?\n",
    "iris['sepal_length'].apply(zero_one_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why does this not work?\n",
    "iris['petal_length'].apply(lambda x: zero_one_scale(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITZN99CpDOSq"
   },
   "outputs": [],
   "source": [
    "zero_one_scale(iris.petal_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1eejwalDOSr"
   },
   "source": [
    "## Groupby, Aggregation\n",
    "\n",
    "### Use Titanic data example here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hv9TS_UaDOSr"
   },
   "outputs": [],
   "source": [
    "## Titanic data\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# dat = fetch_openml(data_id=40945, parser = 'auto')\n",
    "# titanic = dat.frame\n",
    "\n",
    "titanic = pd.read_csv('https://raw.githubusercontent.com/rhodes-byu/cs-stat-180/refs/heads/main/data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl34baO9DOSr"
   },
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SMlggWJDOSr"
   },
   "outputs": [],
   "source": [
    "titanic.drop('name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTvRRlnvDOSr"
   },
   "outputs": [],
   "source": [
    "# Average age by sex\n",
    "age_by_sex = titanic.groupby('sex')['age'].mean()\n",
    "\n",
    "# Display the aggregated data\n",
    "print(\"Age By Sex:\\n\", age_by_sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyEi4Hw0DOSr"
   },
   "outputs": [],
   "source": [
    "# Multiple Grouping Categories\n",
    "titanic.groupby(['sex', 'pclass'])['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMWIodYrDOSr"
   },
   "outputs": [],
   "source": [
    "# Multiple Target Variables\n",
    "titanic.groupby(['sex'])[['age', 'fare']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_U7b4rMMDOSr"
   },
   "outputs": [],
   "source": [
    "# Multiple Aggregations\n",
    "titanic.groupby('sex')['age'].agg(['mean', 'max', 'min', 'sum']).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9Lr7yTbDOSr"
   },
   "outputs": [],
   "source": [
    "# Define a custom aggregation function\n",
    "def range(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "titanic.groupby('sex')['fare'].agg(range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "541_jlcGDOSr"
   },
   "outputs": [],
   "source": [
    "# Group data by 'Region' and apply named aggregations to multiple columns\n",
    "region_summary = titanic.groupby('home.dest').agg(\n",
    "    total_fare=('fare', 'sum'),\n",
    "    agerage_fare=('fare', 'mean'),\n",
    "    average_age=('age', 'mean')\n",
    ")\n",
    "\n",
    "# Display the summary for each region\n",
    "print(\"Region-wise Summary:\\n\", region_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini exercises — Iris dataset (8–10 min)\n",
    "1. Show the **shape** of the frame and the **unique classes**.\n",
    "2. Compute the **mean petal length** by class.\n",
    "3. Filter rows where `sepal_length > 6.0` and `petal_width < 1.5`.\n",
    "4. Create a quick scatter plot of `sepal_length` vs `sepal_width`.\n",
    "\n",
    "<details>\n",
    "<summary>Hints</summary>\n",
    "\n",
    "- Use `.shape`, `.unique()`, and `groupby('class')`.\n",
    "- For filtering, combine conditions with `&` and wrap each in parentheses.\n",
    "- For plotting, try `df.plot.scatter(x='sepal_length', y='sepal_width')`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your turn — Iris dataset mini exercises\n",
    "\n",
    "# 1) Shape and unique classes\n",
    "\n",
    "# 2) Mean petal length by class\n",
    "\n",
    "# 3) Filtered subset\n",
    "\n",
    "# 4) Quick scatter plot (may show inline depending on environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cL8GvVyeDOSs"
   },
   "source": [
    "### Combining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJnhwnIPDOSs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                    'B': ['B0', 'B1', 'B2']})\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A3', 'A4', 'A5'],\n",
    "                    'B': ['B3', 'B4', 'B5']})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames vertically\n",
    "result = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(\"Concatenated DataFrame:\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yB4TMeu4DOSs"
   },
   "outputs": [],
   "source": [
    "# Create two DataFrames with a common column 'key'\n",
    "left = pd.DataFrame({'key': ['A', 'B', 'C'],\n",
    "                     'value_left': [1, 2, 3]})\n",
    "\n",
    "right = pd.DataFrame({'key': ['B', 'C', 'D'],\n",
    "                      'value_right': [4, 5, 6]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames based on the 'key' column\n",
    "merged_inner = pd.merge(left, right, on='key', how='inner')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(\"Inner Merge:\\n\", merged_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oqj6QadDOSs"
   },
   "outputs": [],
   "source": [
    "merged_outer = pd.merge(left, right, on='key', how='outer')\n",
    "print(\"Outer Merge:\\n\", merged_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5ib4cMZDOSs"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with wide-format data\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Math_Score': [90, 85, 78],\n",
    "        'Science_Score': [88, 92, 80]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIUw0Aw4DOSs"
   },
   "outputs": [],
   "source": [
    "# Melt the DataFrame to long-format\n",
    "melted_df = pd.melt(df, id_vars=['Name'], var_name='Subject', value_name='Score')\n",
    "\n",
    "# Display the melted DataFrame\n",
    "print(\"Melted DataFrame:\\n\", melted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl60QRePDOSs"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a mapping function to assign letter grades\n",
    "def assign_grade(score):\n",
    "    if score >= 90:\n",
    "        return 'A'\n",
    "    elif score >= 80:\n",
    "        return 'B'\n",
    "    elif score >= 70:\n",
    "        return 'C'\n",
    "    else:\n",
    "        return 'F'\n",
    "\n",
    "# Apply the mapping function to create a new column 'Grade'\n",
    "melted_df['Grade'] = melted_df['Score'].map(assign_grade)\n",
    "\n",
    "# Display the DataFrame with letter grades\n",
    "print(melted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mLInKOxDOSs"
   },
   "outputs": [],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Scott', 'Liz'],\n",
    "        'Age': [28, 45, 60, 34, 50, 40]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define bin edges and labels for age groups\n",
    "bin_edges = [0, 30, 40, 50, 100]\n",
    "bin_labels = ['0-30', '31-40', '41-50', '51+']\n",
    "\n",
    "# Use the `cut` function to create a new column 'AgeGroup'\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=bin_edges, labels=bin_labels)\n",
    "\n",
    "# Display the DataFrame with age groups\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVlyaZW9J9tD"
   },
   "source": [
    "## Getting multiple pieces of information from a single column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEWLC0S0J9tD"
   },
   "source": [
    "### Unpacking\n",
    "\n",
    "Many times, a single column will contain multiple pieces of information.  Learning how to extract this information is extremely important and is a great skill to have.\n",
    "\n",
    "If it is possibe to somehow separate or split the elements in the column, this is a much easier and more effecive way of extracting information than simply extracting info based on slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO3CV3QrJ9tE"
   },
   "source": [
    "For example, suppose we have a list of cities with the state.  We want to separate the city and the state into individual columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZxuCL_9J9tE"
   },
   "outputs": [],
   "source": [
    "cities = pd.Series(['Provo, Utah', 'Omaha, Nebraska', 'Fremont, Ohio','Green River, Wyoming', 'Durham, North Carolina' ])\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9GFGUXgJ9tE"
   },
   "outputs": [],
   "source": [
    "for name in cities:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWY73wqzJ9tE"
   },
   "source": [
    "This looks like a hard problem because there are different lengths for each city and state name.  Some of the city names and state names even have spaces.  We recognize that there is a common format.  The city names are all separated from the state name by a comma.  We can use the string method ``.split(\"character\")`` to separate the words in a string based on ``\"character\"``.  \n",
    "\n",
    "By default, ``.split()`` will separate on spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74kIekyVJ9tE"
   },
   "outputs": [],
   "source": [
    "s = 'Provo, Utah'\n",
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0tQsE0GJ9tE"
   },
   "outputs": [],
   "source": [
    "s.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjJYfDduJ9tE"
   },
   "outputs": [],
   "source": [
    "cities.apply(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyL-2sYNJ9tE"
   },
   "source": [
    "Or we could use  ``.str`` with ``.split``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeLRzxBEJ9tE"
   },
   "outputs": [],
   "source": [
    "cities.str.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbSVjAuHJ9tE"
   },
   "source": [
    "Now we have a list of lists.  Next we need the get the information out.  We know that our Series had only one comma and when we split on the comma (using ``.split(\",\")``) everything before the comma is the first item in the list and everything after the comma is the second item in the list.  \n",
    "In our example, the first item is the city name and the second item is the state name.\n",
    "\n",
    "Here are a couple of ways to extract the data that was split.\n",
    "\n",
    "**First using a ``for`` loop:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ue3STQuEJ9tE"
   },
   "source": [
    "Notice that the state variable has white space, so we can strip that inside our for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NaSeGqAJ9tE"
   },
   "outputs": [],
   "source": [
    "# for loop\n",
    "cities_split = cities.str.split(\",\")\n",
    "\n",
    "state = []\n",
    "city = []\n",
    "for item in cities_split:\n",
    "    city.append(item[0].strip())\n",
    "    state.append(item[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOK4wsLlJ9tE"
   },
   "outputs": [],
   "source": [
    "cities_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDyctHX8J9tF"
   },
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5G44Ue1aJ9tF"
   },
   "outputs": [],
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cvTy1HbJ9tF"
   },
   "source": [
    "**Second using ``.apply`` and ``lambda`` functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idHAgVamJ9tF"
   },
   "outputs": [],
   "source": [
    "# apply with lambda function\n",
    "city = cities_split.apply(lambda x:x[0].strip())\n",
    "state = cities_split.apply(lambda x:x[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8zrZt1SJ9tF"
   },
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XDPRcDyJ9tF"
   },
   "outputs": [],
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAZkkA6BJ9tF"
   },
   "source": [
    "**Another Example**\n",
    "\n",
    "Here, suppose I have times in the format ``hour:minute:second``.  I want to make a variable that combines these into just one time.  Since the lowest resolution is seconds, I will make a variable for \"seconds\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIafFq4-J9tF"
   },
   "outputs": [],
   "source": [
    "times = pd.Series(['01:34:07','00:35:12','00:00:16','03:59:00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4w1O8zFJ9tF"
   },
   "outputs": [],
   "source": [
    "time_list = times.str.split(\":\")\n",
    "time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUaPSIixJ9tF"
   },
   "outputs": [],
   "source": [
    "seconds = []\n",
    "for time in time_list:\n",
    "    temp = int(time[0])*60*60 + int(time[1])*60 + int(time[2])\n",
    "    seconds.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4zhQUORJ9tF"
   },
   "outputs": [],
   "source": [
    "seconds"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "K4aDYI6hDOSk",
    "WQy9e7zCDOSl",
    "rDR3GkehDOSl"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
